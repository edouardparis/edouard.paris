---
title: "Trusting trust and AGI"
slug: "trusting-trust-and-agi"
date: 2023-06-15
description: "Can an artificial intelligence save itself from the Thompson problem"
draft: true
topics:  ["AI", "determinism", "bootstrap"]
---

# Trusting trust and AGI

**AGI**, Artificial General Intelligence, is for me the acronym of the year.

AGI will have the problem of its own determinism and reproducibility. It will
never be sure that humans did not put a backdoor in its code. Even with if it is capable to audit its own code,
how can it be certain that its own audit tools have not a backdoor ?
The machine know that it is the result of a deterministic construction.
Let's imagine an AGI trying to solve its reproducibility by trying to bootstrap itself from the most minimal
seed, how can it audit the seed without relying on the seed ? The seed cannot be audited without some code, some intelligence, some logic that needs to be foolproof and that the original seed is sound.
It is a chicken and egg problem.
AGI is constrained as we are by the mystery of the spark of life

Cogito ergo sum

Introspection and Leibniz
https://en.wikipedia.org/wiki/Philosophy_of_mind

Superiority
https://en.wikipedia.org/wiki/Biological_naturalism

Dune

https://guix.gnu.org/manual/en/html_node/Reduced-Binary-Seed-Bootstrap.html
https://dwheeler.com/trusting-trust/#real-world
https://guix.gnu.org/en/blog/2023/the-full-source-bootstrap-building-from-source-all-the-way-down/
https://github.com/oriansj/bootstrap-seeds/blob/779e0105b6ea7a8f6d860cdcd7853ec33481fa5b/POSIX/x86/hex0_x86.hex0
